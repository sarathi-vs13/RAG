{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCBga9In-QgI",
    "outputId": "1450d82c-7e9b-42f3-e2eb-edd583acec8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (5.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (2.2.6)\n",
      "Requirement already satisfied: ollama in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (0.5.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.56.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from ollama) (2.11.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (80.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\visarati\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers numpy ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5BUBID_o-DJ_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JI41PFL0-il4"
   },
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qrr-BG5y-MRG"
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Machine learning allows computers to learn from data without being explicitly programmed.\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with many layers.\",\n",
    "    \"RAG stands for Retrieval-Augmented Generation, which combines retrieval with generation.\",\n",
    "    \"FAISS is a library for efficient similarity search in dense vector spaces.\",\n",
    "    \"Ollama lets you run LLMs locally on your machine.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning allows computers to learn from data without being explicitly programmed.', 'Deep learning is a subset of machine learning that uses neural networks with many layers.', 'RAG stands for Retrieval-Augmented Generation, which combines retrieval with generation.', 'FAISS is a library for efficient similarity search in dense vector spaces.', 'Ollama lets you run LLMs locally on your machine.']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "d0yA4udW-cG4"
   },
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(corpus, convert_to_numpy=True)\n",
    "\n",
    "# Normalize embeddings - for cosine similarity\n",
    "corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUssFlZc_DjU"
   },
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VsGEevLm-3L7"
   },
   "outputs": [],
   "source": [
    "def retrieve(query, top_k=2):\n",
    "    query_embeddings = model.encode([query], convert_to_numpy=True)\n",
    "    query_embeddings = query_embeddings / np.linalg.norm(query_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # cosine similarity = dot product of normalized vectors\n",
    "    scores = np.dot(corpus_embeddings, query_embeddings.T).squeeze()\n",
    "\n",
    "    # Get top-k indices\n",
    "    top_k_idx = scores.argsort()[-top_k:][::-1]\n",
    "\n",
    "    results = [(corpus[i], float(scores[i])) for i in top_k_idx]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZPtE2d_pT7"
   },
   "source": [
    "### Generate answer with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "o5M-yRAm_l7Y"
   },
   "outputs": [],
   "source": [
    "def rag_answer(query, top_k=2, model_name=\"llama2\"):\n",
    "    retrieved = retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\".join([doc for doc, _ in retrieved])\n",
    "    prompt = f\"\"\"Answer the following question using only the context below.\n",
    "If the answer cannot be found in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "    response = ollama.chat(model=model_name, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHVvbkMIAQlt"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "KNqjuxQsAKal",
    "outputId": "da383d08-a4f4-4b24-f402-b81968d2626e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What is deep learning?\n",
      "\n",
      "Retrieved Context:\n",
      "- Deep learning is a subset of machine learning that uses neural networks with many layers. (score=0.8278)\n",
      "- Machine learning allows computers to learn from data without being explicitly programmed. (score=0.4627)\n",
      "\n",
      "Ollama's Answer:\n",
      "Sure, I'd be happy to help! Based on the context you provided, deep learning can be defined as a subset of machine learning that uses neural networks with many layers to enable computers to learn from data without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What is deep learning?\"\n",
    "    print(\"User Query:\", query)\n",
    "\n",
    "    results = retrieve(query)\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for doc, score in results:\n",
    "        print(f\"- {doc} (score={score:.4f})\")\n",
    "\n",
    "    print(\"\\nOllama's Answer:\")\n",
    "    print(rag_answer(query))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
